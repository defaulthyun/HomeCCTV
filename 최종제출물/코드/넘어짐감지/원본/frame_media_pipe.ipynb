{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fFXalwOokf2h"},"outputs":[],"source":["import cv2\n","\n","count = 0\n","for chu in range(0,25):\n","    for i in range(1,9):\n","        # 영상 열기\n","        vidcap = cv2.VideoCapture(f'project_3\\\\project_3\\\\train\\\\chute{chu}\\\\cam{i}.avi')\n","        # 영상기준 0.5 초에 들어가는 Frame수\n","        print('영상 프레임' , vidcap.get(cv2.CAP_PROP_FPS))\n","        vid_fps = 0.5 / ( 1 / float(vidcap.get(cv2.CAP_PROP_FPS)))\n","        print('0.5초 간격 프레임' , vid_fps)\n","\n","        while(vidcap.isOpened()):\n","            ret, image = vidcap.read()\n","            if(int(vidcap.get(1)) % (vid_fps/5)  == 0):\n","                print('Saved frame number : ' + str(int(vidcap.get(1))))\n","                cv2.imwrite(\"project_3\\\\project_3\\\\train_frame_images/frame_%d.jpg\" % count, image)\n","                print('Saved frame%d.jpg' % count)\n","                count += 1\n","            if int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)) < int(vidcap.get(1)) + vid_fps:\n","                break\n","\n"]},{"cell_type":"code","source":["!pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9r-05UGG1NBV","executionInfo":{"status":"ok","timestamp":1678846814361,"user_tz":-540,"elapsed":12136,"user":{"displayName":"박상욱","userId":"03476809252527486906"}},"outputId":"ba20d6f1-9a01-421c-b25d-6f32a8bc1e83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.9.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.5.3)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.19.6)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.6.0.66)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.22.4)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (23.3.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.15.0)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.9.1.0\n"]}]},{"cell_type":"code","source":["import mediapipe as mp\n","import pandas as pd\n","import cv2\n","mp_drawing = mp.solutions.drawing_utils\n","mp_drawing_styles = mp.solutions.drawing_styles\n","mp_pose = mp.solutions.pose\n","\n","col = ['nose_x', 'nose_y', 'nose_z', 'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_z','right_shoulder_x','right_shoulder_y', 'right_shoulder_z',\n","      'left_elbow_x','left_elbow_y',' left_elbow_z','right_elbow_x','right_elbow_y','right_elbow_z',\n","       'left_wrist_x','left_wrist_y','left_wrist_z','right_wrist_x','right_wrist_y','right_wrist_z',\n","       'left_hip_x','left_hip_y','left_hip_z', 'right_hip_x', 'right_hip_y','right_hip_z','left_knee_x','left_knee_y','left_knee_z',\n","       'right_knee_x','right_knee_y','right_knee_z','left_ankle_x','left_ankle_y','left_ankle_z','right_ankle_x','right_ankle_y','right_ankle_z']\n","\n","# data = pd.DataFrame(columns=col)\n","\n","data = pd.DataFrame()\n","for i in range(1,11):\n","  # 0 ~ 4523\n","  img1 = f'img/train ({i}).png'\n","    #project_3\\project_3\\train_frame_images\\frame_0.jpg\n","  IMAGE_FILES = [img1]\n","  BG_COLOR = (192, 192, 192)  # 회색\n","  with mp_pose.Pose(\n","          static_image_mode=True,\n","          model_complexity=2,\n","          enable_segmentation=True,\n","          min_detection_confidence=0.5) as pose:\n","      for idx, file in enumerate(IMAGE_FILES):\n","          image = cv2.imread(file)\n","          image_height, image_width, _ = image.shape\n","          # 처리 전 BGR 이미지를 RGB로 변환합니다.\n","          results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","          datas = []\n","          if not results.pose_landmarks:\n","            for i in range(0, 39):\n","                datas.append([0])\n","          else:\n","            for n in range(0,39,3):\n","              cate = col[n][:-2].upper()\n","              datas.append([results.pose_landmarks.landmark[mp_pose.PoseLandmark[cate]].x])\n","              datas.append([results.pose_landmarks.landmark[mp_pose.PoseLandmark[cate]].y])\n","              datas.append([results.pose_landmarks.landmark[mp_pose.PoseLandmark[cate]].z])\n","          data = data.append(pd.Series(datas), ignore_index=True)\n","\n","data.to_csv('data.csv', index=False)\n","\n","\n","# vidcap.release()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249},"id":"aFNP6a-6ki6l","executionInfo":{"status":"error","timestamp":1678776037054,"user_tz":-540,"elapsed":1377,"user":{"displayName":"박상욱","userId":"03476809252527486906"}},"outputId":"f4c9ab82-6353-488b-e959-b843763a95cf"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-ea0f116dc6ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_FILES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           \u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m           \u001b[0;31m# 처리 전 BGR 이미지를 RGB로 변환합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"kwI9V8Av1Ltf"},"execution_count":null,"outputs":[]}]}